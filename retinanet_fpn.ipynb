{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone Detection - RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.ops.boxes import box_iou\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "# Local nbutils.py\n",
    "import nbutils\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./data/drone-detection/drone-detection-new.v5-new-train.yolov8/train\"\n",
    "images_path = os.path.join(base_path, \"images\")\n",
    "labels_path = os.path.join(base_path, \"labels\")\n",
    "\n",
    "df = nbutils.create_dataset(images_path, labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbutils.view_df_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class mappings\n",
    "CLASS_MAPPING = {\"AIRPLANE\": 0, \"DRONE\": 1, \"HELICOPTER\": 2}\n",
    "\n",
    "# Custom Dataset\n",
    "class DroneDetectionDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "        self.image_paths = dataframe[\"image_path\"].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Get all annotations for this image\n",
    "        records = self.df[self.df[\"image_path\"] == image_path]\n",
    "\n",
    "        # Convert normalized YOLO box format to absolute pixel values\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        img_width, img_height = image.size\n",
    "\n",
    "        for _, row in records.iterrows():\n",
    "            x_center = row[\"x_center\"] * img_width\n",
    "            y_center = row[\"y_center\"] * img_height\n",
    "            width = row[\"width\"] * img_width\n",
    "            height = row[\"height\"] * img_height\n",
    "\n",
    "            # Convert YOLO format (x_center, y_center, width, height) to (x_min, y_min, x_max, y_max)\n",
    "            x_min = x_center - width / 2\n",
    "            y_min = y_center - height / 2\n",
    "            x_max = x_center + width / 2\n",
    "            y_max = y_center + height / 2\n",
    "\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            labels.append(CLASS_MAPPING[row[\"class\"]])\n",
    "\n",
    "        # Convert to tensors\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Prepare target dictionary\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "        return image, target\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DroneDetectionDataset(df, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained RetinaNet with FPN\n",
    "model = retinanet_resnet50_fpn(pretrained=True)\n",
    "num_classes = 4  # Background + 3 object classes\n",
    "\n",
    "# Modify classifier to match the number of classes\n",
    "in_features = model.head.classification_head.conv[0].in_channels\n",
    "num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "model.head.classification_head.num_classes = num_classes\n",
    "model.head.classification_head.conv = torch.nn.Conv2d(in_features, num_anchors * num_classes, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 10\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, targets in dataloader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_one_epoch(model, optimizer, dataloader, device)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path, device):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Test inference\n",
    "image_path = \"test_image.jpg\"  # Replace with a real image path\n",
    "predictions = predict(model, image_path, device)\n",
    "\n",
    "# Display results\n",
    "for i, (box, label, score) in enumerate(zip(predictions[0][\"boxes\"], predictions[0][\"labels\"], predictions[0][\"scores\"])):\n",
    "    if score > 0.5:  # Filter out low-confidence detections\n",
    "        print(f\"Object {i}: Class {label.item()}, Score: {score.item()}, Box: {box.tolist()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
